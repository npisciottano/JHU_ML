{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 12 - Neural Networks image recognition\n",
    "Use both MLNN and the ConvNet to solve the following problem.\n",
    "\n",
    "1. Add random noise (i.e. `np.random.normal`) to the images in training and testing. Make sure each image gets a different noise feature added to it. Inspect by printing out an image. \n",
    "2. Compare the loss/accuracy (train, val) after N epochs for both MLNN and ConvNet with and without noise. \n",
    "3. Vary the amount of noise (multiply `np.random.normal` by a factor) and keep track of the accuracy and loss (for training and validation) and plot these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks - Image Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Neural Network\n",
    "Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "plt.imshow(x_train[0])\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.2442 - acc: 0.9249 - val_loss: 0.1165 - val_acc: 0.9634\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1049 - acc: 0.9683 - val_loss: 0.0856 - val_acc: 0.9746\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.0765 - acc: 0.9768 - val_loss: 0.0711 - val_acc: 0.9791\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.0613 - acc: 0.9816 - val_loss: 0.0739 - val_acc: 0.9797\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.0493 - acc: 0.9852 - val_loss: 0.0813 - val_acc: 0.9785\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.0440 - acc: 0.9869 - val_loss: 0.0799 - val_acc: 0.9787\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.0382 - acc: 0.9884 - val_loss: 0.0842 - val_acc: 0.9810\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.0344 - acc: 0.9896 - val_loss: 0.0771 - val_acc: 0.9831\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.0303 - acc: 0.9911 - val_loss: 0.0764 - val_acc: 0.9851\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.0298 - acc: 0.9910 - val_loss: 0.0883 - val_acc: 0.9848\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.0266 - acc: 0.9923 - val_loss: 0.0855 - val_acc: 0.9824\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.0239 - acc: 0.9933 - val_loss: 0.0948 - val_acc: 0.9817\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.0243 - acc: 0.9930 - val_loss: 0.0907 - val_acc: 0.9818\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.0243 - acc: 0.9936 - val_loss: 0.0805 - val_acc: 0.9860\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.0221 - acc: 0.9937 - val_loss: 0.1059 - val_acc: 0.9825\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.0229 - acc: 0.9939 - val_loss: 0.0934 - val_acc: 0.9846\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0206 - acc: 0.9944 - val_loss: 0.1106 - val_acc: 0.9827\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.0213 - acc: 0.9945 - val_loss: 0.1140 - val_acc: 0.9833\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.0191 - acc: 0.9952 - val_loss: 0.1178 - val_acc: 0.9819\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.0182 - acc: 0.9950 - val_loss: 0.1089 - val_acc: 0.9841\n",
      "Test loss: 0.1088642166149808\n",
      "Test accuracy: 0.9841\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv Net\n",
    "Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if backend.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.2689 - acc: 0.9164 - val_loss: 0.0645 - val_acc: 0.9781\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.0926 - acc: 0.9718 - val_loss: 0.0427 - val_acc: 0.9856\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.0689 - acc: 0.9798 - val_loss: 0.0401 - val_acc: 0.9855\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.0542 - acc: 0.9836 - val_loss: 0.0338 - val_acc: 0.9883\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.0484 - acc: 0.9853 - val_loss: 0.0292 - val_acc: 0.9901\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.0435 - acc: 0.9868 - val_loss: 0.0302 - val_acc: 0.9898\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.0393 - acc: 0.9879 - val_loss: 0.0276 - val_acc: 0.9910\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 123s 2ms/step - loss: 0.0339 - acc: 0.9891 - val_loss: 0.0288 - val_acc: 0.9905\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 108s 2ms/step - loss: 0.0310 - acc: 0.9909 - val_loss: 0.0255 - val_acc: 0.9923\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0308 - acc: 0.9902 - val_loss: 0.0299 - val_acc: 0.9900\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 110s 2ms/step - loss: 0.0276 - acc: 0.9913 - val_loss: 0.0281 - val_acc: 0.9907\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 101s 2ms/step - loss: 0.0274 - acc: 0.9917 - val_loss: 0.0246 - val_acc: 0.9917\n",
      "Test loss: 0.024602045932716282\n",
      "Test accuracy: 0.9917\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## With noise added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adding noise to the image\n",
    "(noisy_xtrain, noisy_ytrain), (noisy_xtest, noisy_ytest) = mnist.load_data()\n",
    "noisy_xtrain = noisy_xtrain+np.random.normal(noisy_xtrain, 50)\n",
    "noisy_xtest = noisy_xtest+np.random.normal(noisy_xtest, 50)\n",
    "plt.imshow(noisy_xtrain[0])\n",
    "\n",
    "noisy_xtrain = noisy_xtrain.reshape(60000, 784)\n",
    "noisy_xtest = noisy_xtest.reshape(10000, 784)\n",
    "noisy_xtrain = noisy_xtrain.astype('float32')\n",
    "noisy_xtest = noisy_xtest.astype('float32')\n",
    "noisy_xtrain /= 255\n",
    "noisy_xtest /= 255\n",
    "print(noisy_xtrain.shape[0], 'train samples')\n",
    "print(noisy_xtest.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.2647 - acc: 0.9177 - val_loss: 0.1159 - val_acc: 0.9627\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.1010 - acc: 0.9693 - val_loss: 0.1092 - val_acc: 0.9672\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0639 - acc: 0.9799 - val_loss: 0.0959 - val_acc: 0.9747\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0454 - acc: 0.9862 - val_loss: 0.1188 - val_acc: 0.9720\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0370 - acc: 0.9886 - val_loss: 0.1161 - val_acc: 0.9749\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0313 - acc: 0.9908 - val_loss: 0.1140 - val_acc: 0.9763\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0250 - acc: 0.9928 - val_loss: 0.1374 - val_acc: 0.9754\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0226 - acc: 0.9936 - val_loss: 0.1335 - val_acc: 0.9772\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0222 - acc: 0.9938 - val_loss: 0.1824 - val_acc: 0.9714\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.0194 - acc: 0.9945 - val_loss: 0.1407 - val_acc: 0.9776\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.0174 - acc: 0.9952 - val_loss: 0.1542 - val_acc: 0.9772\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0163 - acc: 0.9954 - val_loss: 0.1609 - val_acc: 0.9759\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.0143 - acc: 0.9960 - val_loss: 0.1856 - val_acc: 0.9767\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0161 - acc: 0.9957 - val_loss: 0.1590 - val_acc: 0.9777\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0137 - acc: 0.9966 - val_loss: 0.1788 - val_acc: 0.9772\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0149 - acc: 0.9960 - val_loss: 0.1632 - val_acc: 0.9791\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0135 - acc: 0.9968 - val_loss: 0.1755 - val_acc: 0.9787\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0143 - acc: 0.9967 - val_loss: 0.1676 - val_acc: 0.9791\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0128 - acc: 0.9965 - val_loss: 0.1750 - val_acc: 0.9791\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0129 - acc: 0.9970 - val_loss: 0.2025 - val_acc: 0.9757\n",
      "Test loss: 0.17094243237429488\n",
      "Test accuracy: 0.9787\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "\n",
    "noisy_ytrain = keras.utils.to_categorical(noisy_ytrain, num_classes)\n",
    "noisy_ytest = keras.utils.to_categorical(noisy_ytest, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(noisy_xtrain, noisy_ytrain,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(noisy_xtest, noisy_ytest))\n",
    "score50 = model.evaluate(noisy_xtest, noisy_ytest, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2025147488194846, 0.9757]\n"
     ]
    }
   ],
   "source": [
    "print(score50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.2420 - acc: 0.9256 - val_loss: 0.1142 - val_acc: 0.9642\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.1042 - acc: 0.9688 - val_loss: 0.0917 - val_acc: 0.9748\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0784 - acc: 0.9767 - val_loss: 0.0914 - val_acc: 0.9743\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0650 - acc: 0.9801 - val_loss: 0.1064 - val_acc: 0.9750\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.0542 - acc: 0.9840 - val_loss: 0.0847 - val_acc: 0.9791\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0494 - acc: 0.9856 - val_loss: 0.0880 - val_acc: 0.9796\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0452 - acc: 0.9868 - val_loss: 0.0812 - val_acc: 0.9799\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0401 - acc: 0.9890 - val_loss: 0.0931 - val_acc: 0.9804\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0387 - acc: 0.9892 - val_loss: 0.1005 - val_acc: 0.9808\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0376 - acc: 0.9900 - val_loss: 0.1003 - val_acc: 0.9819\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0340 - acc: 0.9913 - val_loss: 0.1008 - val_acc: 0.9824\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0347 - acc: 0.9907 - val_loss: 0.0851 - val_acc: 0.9844\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.0321 - acc: 0.9922 - val_loss: 0.1010 - val_acc: 0.9840\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0301 - acc: 0.9922 - val_loss: 0.1185 - val_acc: 0.9812\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0278 - acc: 0.9932 - val_loss: 0.1235 - val_acc: 0.9810\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0280 - acc: 0.9935 - val_loss: 0.1133 - val_acc: 0.9830\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0292 - acc: 0.9933 - val_loss: 0.1187 - val_acc: 0.9835\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0266 - acc: 0.9938 - val_loss: 0.1334 - val_acc: 0.9816\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0255 - acc: 0.9943 - val_loss: 0.1391 - val_acc: 0.9809\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0270 - acc: 0.9938 - val_loss: 0.1236 - val_acc: 0.9818\n",
      "10\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.2454 - acc: 0.9254 - val_loss: 0.1008 - val_acc: 0.9686\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.1042 - acc: 0.9692 - val_loss: 0.0879 - val_acc: 0.9734\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0746 - acc: 0.9779 - val_loss: 0.0758 - val_acc: 0.9792\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.0599 - acc: 0.9822 - val_loss: 0.0867 - val_acc: 0.9782\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0513 - acc: 0.9844 - val_loss: 0.0796 - val_acc: 0.9804\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0443 - acc: 0.9871 - val_loss: 0.0812 - val_acc: 0.9797\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0389 - acc: 0.9886 - val_loss: 0.0973 - val_acc: 0.9800\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0344 - acc: 0.9898 - val_loss: 0.0929 - val_acc: 0.9820\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0304 - acc: 0.9914 - val_loss: 0.1014 - val_acc: 0.9812\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0296 - acc: 0.9916 - val_loss: 0.1134 - val_acc: 0.9810\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0291 - acc: 0.9925 - val_loss: 0.0977 - val_acc: 0.9838\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0272 - acc: 0.9929 - val_loss: 0.1174 - val_acc: 0.9812\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0248 - acc: 0.9931 - val_loss: 0.1081 - val_acc: 0.9829\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0237 - acc: 0.9940 - val_loss: 0.1074 - val_acc: 0.9836\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0236 - acc: 0.9942 - val_loss: 0.1345 - val_acc: 0.9807\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0240 - acc: 0.9940 - val_loss: 0.1332 - val_acc: 0.9798\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0232 - acc: 0.9947 - val_loss: 0.1241 - val_acc: 0.9824\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0207 - acc: 0.9950 - val_loss: 0.1222 - val_acc: 0.9829\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0199 - acc: 0.9955 - val_loss: 0.1225 - val_acc: 0.9837\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0211 - acc: 0.9953 - val_loss: 0.1123 - val_acc: 0.9851\n",
      "20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.2485 - acc: 0.9233 - val_loss: 0.1151 - val_acc: 0.9629\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.1034 - acc: 0.9688 - val_loss: 0.0924 - val_acc: 0.9723\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.0721 - acc: 0.9785 - val_loss: 0.0783 - val_acc: 0.9765\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0538 - acc: 0.9841 - val_loss: 0.0814 - val_acc: 0.9790\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0467 - acc: 0.9860 - val_loss: 0.0920 - val_acc: 0.9784\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0364 - acc: 0.9889 - val_loss: 0.1064 - val_acc: 0.9760\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0325 - acc: 0.9901 - val_loss: 0.1038 - val_acc: 0.9779\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0321 - acc: 0.9912 - val_loss: 0.0983 - val_acc: 0.9813\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.0271 - acc: 0.9926 - val_loss: 0.1094 - val_acc: 0.9807\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0241 - acc: 0.9931 - val_loss: 0.1133 - val_acc: 0.9811\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.0201 - acc: 0.9943 - val_loss: 0.1227 - val_acc: 0.9798\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0213 - acc: 0.9943 - val_loss: 0.1313 - val_acc: 0.9781\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0216 - acc: 0.9944 - val_loss: 0.1280 - val_acc: 0.9817\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0202 - acc: 0.9948 - val_loss: 0.1227 - val_acc: 0.9832\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0195 - acc: 0.9952 - val_loss: 0.1324 - val_acc: 0.9797\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0184 - acc: 0.9952 - val_loss: 0.1375 - val_acc: 0.9791\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0199 - acc: 0.9953 - val_loss: 0.1306 - val_acc: 0.9808\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0162 - acc: 0.9963 - val_loss: 0.1198 - val_acc: 0.9832\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0168 - acc: 0.9960 - val_loss: 0.1424 - val_acc: 0.9808\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0171 - acc: 0.9959 - val_loss: 0.1336 - val_acc: 0.9820\n",
      "30\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.2504 - acc: 0.9223 - val_loss: 0.0997 - val_acc: 0.9703\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0998 - acc: 0.9700 - val_loss: 0.0962 - val_acc: 0.9697\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0683 - acc: 0.9796 - val_loss: 0.1120 - val_acc: 0.9686\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0527 - acc: 0.9845 - val_loss: 0.0925 - val_acc: 0.9763\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0423 - acc: 0.9879 - val_loss: 0.0795 - val_acc: 0.9796\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.0337 - acc: 0.9896 - val_loss: 0.0987 - val_acc: 0.9786\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0290 - acc: 0.9913 - val_loss: 0.0999 - val_acc: 0.9804\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0270 - acc: 0.9928 - val_loss: 0.1034 - val_acc: 0.9801\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0258 - acc: 0.9932 - val_loss: 0.1195 - val_acc: 0.9802\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0233 - acc: 0.9934 - val_loss: 0.1283 - val_acc: 0.9802\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0224 - acc: 0.9941 - val_loss: 0.1259 - val_acc: 0.9800\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0189 - acc: 0.9951 - val_loss: 0.1522 - val_acc: 0.9786\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0211 - acc: 0.9948 - val_loss: 0.1227 - val_acc: 0.9817\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0199 - acc: 0.9951 - val_loss: 0.1403 - val_acc: 0.9805\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0174 - acc: 0.9955 - val_loss: 0.1420 - val_acc: 0.9808\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0182 - acc: 0.9958 - val_loss: 0.1304 - val_acc: 0.9826\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0174 - acc: 0.9957 - val_loss: 0.1386 - val_acc: 0.9814\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0167 - acc: 0.9960 - val_loss: 0.1341 - val_acc: 0.9836\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 92us/step - loss: 0.0198 - acc: 0.9956 - val_loss: 0.1451 - val_acc: 0.9816\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0149 - acc: 0.9966 - val_loss: 0.1371 - val_acc: 0.9817\n",
      "40\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.2524 - acc: 0.9212 - val_loss: 0.1159 - val_acc: 0.9631\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0996 - acc: 0.9697 - val_loss: 0.1156 - val_acc: 0.9654\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0668 - acc: 0.9790 - val_loss: 0.0938 - val_acc: 0.9755\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0482 - acc: 0.9853 - val_loss: 0.0948 - val_acc: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0365 - acc: 0.9885 - val_loss: 0.1143 - val_acc: 0.9763\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.0308 - acc: 0.9904 - val_loss: 0.1576 - val_acc: 0.9698\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0275 - acc: 0.9921 - val_loss: 0.1267 - val_acc: 0.9767\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0252 - acc: 0.9927 - val_loss: 0.1207 - val_acc: 0.9796\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0229 - acc: 0.9937 - val_loss: 0.1248 - val_acc: 0.9795\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0188 - acc: 0.9949 - val_loss: 0.1459 - val_acc: 0.9774\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.0191 - acc: 0.9945 - val_loss: 0.1288 - val_acc: 0.9798\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0174 - acc: 0.9952 - val_loss: 0.1390 - val_acc: 0.9782\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0152 - acc: 0.9959 - val_loss: 0.1567 - val_acc: 0.9774\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0156 - acc: 0.9961 - val_loss: 0.1633 - val_acc: 0.9774\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0154 - acc: 0.9964 - val_loss: 0.1574 - val_acc: 0.9793\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0149 - acc: 0.9960 - val_loss: 0.1769 - val_acc: 0.9782\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0150 - acc: 0.9965 - val_loss: 0.1463 - val_acc: 0.9807\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0141 - acc: 0.9964 - val_loss: 0.1739 - val_acc: 0.9788\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.0136 - acc: 0.9968 - val_loss: 0.1691 - val_acc: 0.9785\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0144 - acc: 0.9969 - val_loss: 0.1833 - val_acc: 0.9779\n",
      "50\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.2599 - acc: 0.9197 - val_loss: 0.1223 - val_acc: 0.9605\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.1008 - acc: 0.9691 - val_loss: 0.1097 - val_acc: 0.9668\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0648 - acc: 0.9802 - val_loss: 0.1140 - val_acc: 0.9692\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0460 - acc: 0.9859 - val_loss: 0.1064 - val_acc: 0.9735\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0373 - acc: 0.9888 - val_loss: 0.1209 - val_acc: 0.9749\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0303 - acc: 0.9915 - val_loss: 0.1254 - val_acc: 0.9745\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0253 - acc: 0.9928 - val_loss: 0.1450 - val_acc: 0.9750\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0226 - acc: 0.9934 - val_loss: 0.1279 - val_acc: 0.9756\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0208 - acc: 0.9939 - val_loss: 0.1385 - val_acc: 0.9777\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0210 - acc: 0.9943 - val_loss: 0.1613 - val_acc: 0.9742\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0186 - acc: 0.9950 - val_loss: 0.1674 - val_acc: 0.9757\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0194 - acc: 0.9948 - val_loss: 0.1828 - val_acc: 0.9743\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0194 - acc: 0.9953 - val_loss: 0.1682 - val_acc: 0.9761\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0173 - acc: 0.9957 - val_loss: 0.1888 - val_acc: 0.9763\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0156 - acc: 0.9961 - val_loss: 0.1749 - val_acc: 0.9775\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0137 - acc: 0.9967 - val_loss: 0.1772 - val_acc: 0.9770\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0143 - acc: 0.9965 - val_loss: 0.1892 - val_acc: 0.9757\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.0138 - acc: 0.9968 - val_loss: 0.1996 - val_acc: 0.9761\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0136 - acc: 0.9969 - val_loss: 0.2070 - val_acc: 0.9759\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.0145 - acc: 0.9968 - val_loss: 0.1781 - val_acc: 0.9772\n",
      "60\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.2727 - acc: 0.9158 - val_loss: 0.1120 - val_acc: 0.9634\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.1037 - acc: 0.9689 - val_loss: 0.1054 - val_acc: 0.9705\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0624 - acc: 0.9809 - val_loss: 0.1193 - val_acc: 0.9672\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0448 - acc: 0.9862 - val_loss: 0.1119 - val_acc: 0.9740\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0339 - acc: 0.9902 - val_loss: 0.1394 - val_acc: 0.9700\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0282 - acc: 0.9916 - val_loss: 0.1281 - val_acc: 0.9750\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0239 - acc: 0.9928 - val_loss: 0.1633 - val_acc: 0.9719\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0211 - acc: 0.9938 - val_loss: 0.1655 - val_acc: 0.9717\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.0211 - acc: 0.9940 - val_loss: 0.1573 - val_acc: 0.9751\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0194 - acc: 0.9947 - val_loss: 0.1662 - val_acc: 0.9737\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0195 - acc: 0.9947 - val_loss: 0.1763 - val_acc: 0.9735\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0164 - acc: 0.9956 - val_loss: 0.1790 - val_acc: 0.9745\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0144 - acc: 0.9960 - val_loss: 0.1881 - val_acc: 0.9744\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0138 - acc: 0.9966 - val_loss: 0.1808 - val_acc: 0.9739\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.0156 - acc: 0.9958 - val_loss: 0.1774 - val_acc: 0.9753\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0150 - acc: 0.9965 - val_loss: 0.2032 - val_acc: 0.9736\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.0144 - acc: 0.9968 - val_loss: 0.1767 - val_acc: 0.9775\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0143 - acc: 0.9966 - val_loss: 0.1825 - val_acc: 0.9785\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0122 - acc: 0.9970 - val_loss: 0.1928 - val_acc: 0.9762\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0128 - acc: 0.9970 - val_loss: 0.1990 - val_acc: 0.9764\n",
      "70\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.2788 - acc: 0.9141 - val_loss: 0.1248 - val_acc: 0.9610\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.1048 - acc: 0.9681 - val_loss: 0.1120 - val_acc: 0.9654\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0616 - acc: 0.9808 - val_loss: 0.1148 - val_acc: 0.9690\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0453 - acc: 0.9861 - val_loss: 0.1178 - val_acc: 0.9718\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0327 - acc: 0.9899 - val_loss: 0.1267 - val_acc: 0.9738\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.0279 - acc: 0.9909 - val_loss: 0.1293 - val_acc: 0.9748\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0254 - acc: 0.9925 - val_loss: 0.1444 - val_acc: 0.9732\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0220 - acc: 0.9942 - val_loss: 0.1741 - val_acc: 0.9730\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0193 - acc: 0.9945 - val_loss: 0.1639 - val_acc: 0.9739\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0184 - acc: 0.9950 - val_loss: 0.1745 - val_acc: 0.9723\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0191 - acc: 0.9949 - val_loss: 0.1769 - val_acc: 0.9740\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0189 - acc: 0.9953 - val_loss: 0.1697 - val_acc: 0.9755\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0143 - acc: 0.9962 - val_loss: 0.2122 - val_acc: 0.9711\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0174 - acc: 0.9960 - val_loss: 0.1810 - val_acc: 0.9740\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0138 - acc: 0.9966 - val_loss: 0.1985 - val_acc: 0.9739\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0137 - acc: 0.9968 - val_loss: 0.1910 - val_acc: 0.9760\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0150 - acc: 0.9967 - val_loss: 0.1997 - val_acc: 0.9759\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0120 - acc: 0.9970 - val_loss: 0.2127 - val_acc: 0.9749\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0135 - acc: 0.9970 - val_loss: 0.2047 - val_acc: 0.9755\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.0139 - acc: 0.9965 - val_loss: 0.2212 - val_acc: 0.9747\n",
      "80\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.2842 - acc: 0.9113 - val_loss: 0.1322 - val_acc: 0.9578\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.1073 - acc: 0.9669 - val_loss: 0.1081 - val_acc: 0.9668\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0617 - acc: 0.9802 - val_loss: 0.1248 - val_acc: 0.9686\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0427 - acc: 0.9867 - val_loss: 0.1284 - val_acc: 0.9694\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0332 - acc: 0.9891 - val_loss: 0.1545 - val_acc: 0.9677\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0296 - acc: 0.9914 - val_loss: 0.1531 - val_acc: 0.9703\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0239 - acc: 0.9930 - val_loss: 0.1607 - val_acc: 0.9709\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.0203 - acc: 0.9938 - val_loss: 0.1746 - val_acc: 0.9699\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.0179 - acc: 0.9948 - val_loss: 0.2048 - val_acc: 0.9706\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0175 - acc: 0.9950 - val_loss: 0.2147 - val_acc: 0.9693\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0166 - acc: 0.9954 - val_loss: 0.2164 - val_acc: 0.9690\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.0158 - acc: 0.9954 - val_loss: 0.2066 - val_acc: 0.9708\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0130 - acc: 0.9963 - val_loss: 0.2152 - val_acc: 0.9714\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0130 - acc: 0.9966 - val_loss: 0.2315 - val_acc: 0.9697\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.0141 - acc: 0.9964 - val_loss: 0.2245 - val_acc: 0.9714\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0130 - acc: 0.9969 - val_loss: 0.2110 - val_acc: 0.9725\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0137 - acc: 0.9968 - val_loss: 0.2362 - val_acc: 0.9705\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0134 - acc: 0.9968 - val_loss: 0.2248 - val_acc: 0.9713\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.0126 - acc: 0.9970 - val_loss: 0.2330 - val_acc: 0.9724\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0119 - acc: 0.9974 - val_loss: 0.2463 - val_acc: 0.9715\n",
      "90\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.2983 - acc: 0.9072 - val_loss: 0.1422 - val_acc: 0.9539\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.1099 - acc: 0.9667 - val_loss: 0.1253 - val_acc: 0.9651\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0639 - acc: 0.9799 - val_loss: 0.1344 - val_acc: 0.9642\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0426 - acc: 0.9869 - val_loss: 0.1456 - val_acc: 0.9660\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0331 - acc: 0.9895 - val_loss: 0.1793 - val_acc: 0.9653\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0270 - acc: 0.9917 - val_loss: 0.1723 - val_acc: 0.9672\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0248 - acc: 0.9930 - val_loss: 0.2068 - val_acc: 0.9653\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0225 - acc: 0.9932 - val_loss: 0.1973 - val_acc: 0.9662\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0191 - acc: 0.9947 - val_loss: 0.1962 - val_acc: 0.9684\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.0176 - acc: 0.9952 - val_loss: 0.2077 - val_acc: 0.9692\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0165 - acc: 0.9954 - val_loss: 0.2287 - val_acc: 0.9674\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0153 - acc: 0.9956 - val_loss: 0.2282 - val_acc: 0.9692\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0160 - acc: 0.9959 - val_loss: 0.2538 - val_acc: 0.9686\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 92us/step - loss: 0.0175 - acc: 0.9954 - val_loss: 0.2236 - val_acc: 0.9698\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0140 - acc: 0.9965 - val_loss: 0.2590 - val_acc: 0.9672\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0162 - acc: 0.9960 - val_loss: 0.2290 - val_acc: 0.9702\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0153 - acc: 0.9963 - val_loss: 0.2366 - val_acc: 0.9714\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0113 - acc: 0.9971 - val_loss: 0.2572 - val_acc: 0.9705\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 92us/step - loss: 0.0127 - acc: 0.9967 - val_loss: 0.2707 - val_acc: 0.9660\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 92us/step - loss: 0.0124 - acc: 0.9972 - val_loss: 0.2535 - val_acc: 0.9700\n"
     ]
    }
   ],
   "source": [
    "parameters = range(0, 100, 10)\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "allscores=[]\n",
    "\n",
    "for x in parameters:\n",
    "    (noisy_xtrain, noisy_ytrain), (noisy_xtest, noisy_ytest) = mnist.load_data()\n",
    "    noisy_xtrain = noisy_xtrain+np.random.normal(noisy_xtrain, x)\n",
    "    noisy_xtest = noisy_xtest+np.random.normal(noisy_xtest, x)\n",
    "    print(x)\n",
    "\n",
    "    noisy_xtrain = noisy_xtrain.reshape(60000, 784)\n",
    "    noisy_xtest = noisy_xtest.reshape(10000, 784)\n",
    "    noisy_xtrain = noisy_xtrain.astype('float32')\n",
    "    noisy_xtest = noisy_xtest.astype('float32')\n",
    "    noisy_xtrain /= 255\n",
    "    noisy_xtest /= 255\n",
    "    noisy_ytrain = keras.utils.to_categorical(noisy_ytrain, num_classes)\n",
    "    noisy_ytest = keras.utils.to_categorical(noisy_ytest, num_classes)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(noisy_xtrain, noisy_ytrain,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(noisy_xtest, noisy_ytest))\n",
    "    x = model.evaluate(noisy_xtest, noisy_ytest, verbose=0)\n",
    "    allscores.append(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.12360782584783851, 0.9818], [0.1122552095077423, 0.9851], [0.13355721265197434, 0.982], [0.13709209497759575, 0.9817], [0.18334609402565025, 0.9779], [0.1781390108602849, 0.9772], [0.1990449488847319, 0.9764], [0.22120912985443997, 0.9747], [0.246294115037751, 0.9715], [0.25350026728553304, 0.97]]\n"
     ]
    }
   ],
   "source": [
    "print(allscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(allscores)\n",
    "plt.title('Test Accuracy')\n",
    "plt.axis([0,10,.95, 1])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(allscores)\n",
    "plt.title('Test Lost')\n",
    "plt.axis([0,10,.97, 1])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
