{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 12 - Neural Networks image recognition\n",
    "Use both MLNN and the ConvNet to solve the following problem.\n",
    "\n",
    "1. Add random noise (i.e. `np.random.normal`) to the images in training and testing. Make sure each image gets a different noise feature added to it. Inspect by printing out an image. \n",
    "2. Compare the loss/accuracy (train, val) after N epochs for both MLNN and ConvNet with and without noise. \n",
    "3. Vary the amount of noise (multiply `np.random.normal` by a factor) and keep track of the accuracy and loss (for training and validation) and plot these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks - Image Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Neural Network\n",
    "Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADolJREFUeJzt3X2MXOV1x/HfyXq9jo1JvHVsHOJgxzgBYhqTjgzICFwhXKdCMqgCYkWRQ5M4LzgprStBraq4FancKiF1CUVamq1tifcEiv+gSZAVAVFhy+IQXuLwErMli7e7mA3YEOKX3dM/9m60MTvPrGfuzJ3d8/1I1szcc+/co4Hf3pl55t7H3F0A4nlP0Q0AKAbhB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q1LRG7my6tfkMzWrkLoFQfqu3dcQP20TWrSn8ZrZG0jZJLZL+3d23ptafoVk61y6uZZcAErp894TXrfptv5m1SLpF0qcknSVpnZmdVe3zAWisWj7zr5D0krvvc/cjku6StDaftgDUWy3hP1XSr8Y87s2W/R4z22Bm3WbWfVSHa9gdgDzVEv7xvlR41/nB7t7h7iV3L7WqrYbdAchTLeHvlbRwzOMPSdpfWzsAGqWW8D8haamZLTaz6ZI+LWlXPm0BqLeqh/rc/ZiZbZT0Q40M9XW6+3O5dQagrmoa53f3ByU9mFMvABqIn/cCQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QVE2z9JpZj6RDkoYkHXP3Uh5NIT82Lf2fuOUDc+u6/+f/elHZ2tDM4eS2py0ZSNZnftWS9f+7aXrZ2p7S3cltDwy9nayfe++mZP30v3o8WW8GNYU/88fufiCH5wHQQLztB4KqNfwu6Udm9qSZbcijIQCNUevb/pXuvt/M5kl6yMx+4e6PjF0h+6OwQZJmaGaNuwOQl5qO/O6+P7sdkHS/pBXjrNPh7iV3L7WqrZbdAchR1eE3s1lmNnv0vqTVkp7NqzEA9VXL2/75ku43s9HnucPdf5BLVwDqrurwu/s+SZ/IsZcpq+XMpcm6t7Um6/sven+y/s555cek29+XHq9+9BPp8e4i/ddvZifr//SdNcl619l3lK29fPSd5LZb+y9J1j/4qCfrkwFDfUBQhB8IivADQRF+ICjCDwRF+IGg8jirL7yhVZ9M1m/afkuy/tHW8qeeTmVHfShZ/7ubP5esT3s7Pdx2/r0by9Zmv3osuW3bgfRQ4MzurmR9MuDIDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBMc6fg7bn9yfrT/52YbL+0db+PNvJ1aa+85L1fW+lL/29fcn3ytbeHE6P08//1/9O1utp8p+wWxlHfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IytwbN6J5srX7uXZxw/bXLAavPj9ZP7gmfXntlqdPStZ/9tWbT7inUTce+MNk/YmL0uP4Q2+8maz7+eWv7t7z9eSmWrzuZ+kV8C5dvlsHfTA9d3mGIz8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBFVxnN/MOiVdKmnA3Zdly9ol3S1pkaQeSVe6+68r7SzqOH8lLXP/IFkfen0wWX/5jvJj9c9d2JncdsU/fi1Zn3dLcefU48TlPc6/XdLxE6FfL2m3uy+VtDt7DGASqRh+d39E0vGHnrWSdmT3d0i6LOe+ANRZtZ/557t7nyRlt/PyawlAI9T9Gn5mtkHSBkmaoZn13h2ACar2yN9vZgskKbsdKLeiu3e4e8ndS61qq3J3APJWbfh3SVqf3V8v6YF82gHQKBXDb2Z3SnpM0sfMrNfMPi9pq6RLzOxFSZdkjwFMIhU/87v7ujIlBuxzMnTg9Zq2P3pwetXbfvwzP0/WX7u1Jf0Ew0NV7xvF4hd+QFCEHwiK8ANBEX4gKMIPBEX4gaCYonsKOPO6F8rWrj47PSL7H6ftTtYvuuKaZH323Y8n62heHPmBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjG+aeA1DTZr3/lzOS2r+x6J1m//sadyfrfXHl5su4/fV/Z2sJvPJbcVg2cPj4ijvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EFTFKbrzxBTdzWfwz89P1m+/4ZvJ+uJpM6re98d3bkzWl97Wl6wf29dT9b6nqryn6AYwBRF+ICjCDwRF+IGgCD8QFOEHgiL8QFAVx/nNrFPSpZIG3H1ZtmyLpC9Kei1bbbO7P1hpZ4zzTz6+cnmyfvLW3mT9zo/8sOp9n/HjLyTrH/v78tcxkKShF/dVve/JKu9x/u2S1oyz/Nvuvjz7VzH4AJpLxfC7+yOSBhvQC4AGquUz/0Yze9rMOs1sTm4dAWiIasN/q6QlkpZL6pP0rXIrmtkGM+s2s+6jOlzl7gDkrarwu3u/uw+5+7Ck2yStSKzb4e4ldy+1qq3aPgHkrKrwm9mCMQ8vl/RsPu0AaJSKl+42szslrZI018x6Jd0gaZWZLZfkknokfamOPQKoA87nR01a5s9L1vdfdXrZWtd125LbvqfCG9PPvLw6WX/zgteT9amI8/kBVET4gaAIPxAU4QeCIvxAUIQfCIqhPhTmnt70FN0zbXqy/hs/kqxf+rVryz/3/V3JbScrhvoAVET4gaAIPxAU4QeCIvxAUIQfCIrwA0FVPJ8fsQ1fkL509y+vSE/RvWx5T9lapXH8Sm4ePCdZn/lAd03PP9Vx5AeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoBjnn+KstCxZf+Hr6bH221buSNYvnJE+p74Wh/1osv744OL0Ewz35djN1MORHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCqjjOb2YLJe2UdIqkYUkd7r7NzNol3S1pkaQeSVe6+6/r12pc0xaflqz/8uoPlq1tuequ5LZ/dtKBqnrKw+b+UrL+8LbzkvU5O9LX/UfaRI78xyRtcvczJZ0n6RozO0vS9ZJ2u/tSSbuzxwAmiYrhd/c+d9+T3T8kaa+kUyWtlTT6868dki6rV5MA8ndCn/nNbJGkcyR1SZrv7n3SyB8ISfPybg5A/Uw4/GZ2kqTvS7rW3Q+ewHYbzKzbzLqP6nA1PQKogwmF38xaNRL82939vmxxv5ktyOoLJA2Mt627d7h7yd1LrWrLo2cAOagYfjMzSd+VtNfdbxpT2iVpfXZ/vaQH8m8PQL1M5JTelZI+K+kZM3sqW7ZZ0lZJ95jZ5yW9IumK+rQ4+U1b9OFk/c0/WpCsX/UPP0jWv/z++5L1etrUlx6Oe+zfyg/ntW//n+S2c4YZyquniuF3959IKjff98X5tgOgUfiFHxAU4QeCIvxAUIQfCIrwA0ERfiAoLt09QdMWnFK2Ntg5K7ntVxY/nKyvm91fVU952PjqBcn6nlvTU3TP/d6zyXr7IcbqmxVHfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IKsw4/5E/SV8m+shfDibrm09/sGxt9XvfrqqnvPQPvVO2duGuTcltz/jbXyTr7W+kx+mHk1U0M478QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBUmHH+nsvSf+deOPveuu37ljeWJOvbHl6drNtQuSunjzjjxpfL1pb2dyW3HUpWMZVx5AeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoMzd0yuYLZS0U9IpGjl9u8Pdt5nZFklflPRatupmdy9/0rukk63dzzVm9Qbqpct366APpn8YkpnIj3yOSdrk7nvMbLakJ83soaz2bXf/ZrWNAihOxfC7e5+kvuz+ITPbK+nUejcGoL5O6DO/mS2SdI6k0d+MbjSzp82s08zmlNlmg5l1m1n3UR2uqVkA+Zlw+M3sJEnfl3Stux+UdKukJZKWa+SdwbfG287dO9y95O6lVrXl0DKAPEwo/GbWqpHg3+7u90mSu/e7+5C7D0u6TdKK+rUJIG8Vw29mJum7kva6+01jli8Ys9rlktLTtQJoKhP5tn+lpM9KesbMnsqWbZa0zsyWS3JJPZK+VJcOAdTFRL7t/4mk8cYNk2P6AJobv/ADgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EVfHS3bnuzOw1Sf87ZtFcSQca1sCJadbemrUvid6qlWdvp7n7ByayYkPD/66dm3W7e6mwBhKatbdm7Uuit2oV1Rtv+4GgCD8QVNHh7yh4/ynN2luz9iXRW7UK6a3Qz/wAilP0kR9AQQoJv5mtMbPnzewlM7u+iB7KMbMeM3vGzJ4ys+6Ce+k0swEze3bMsnYze8jMXsxux50mraDetpjZq9lr95SZ/WlBvS00sx+b2V4ze87M/iJbXuhrl+irkNet4W/7zaxF0guSLpHUK+kJSevc/ecNbaQMM+uRVHL3wseEzexCSW9J2unuy7Jl/yxp0N23Zn8457j7dU3S2xZJbxU9c3M2ocyCsTNLS7pM0udU4GuX6OtKFfC6FXHkXyHpJXff5+5HJN0laW0BfTQ9d39E0uBxi9dK2pHd36GR/3karkxvTcHd+9x9T3b/kKTRmaULfe0SfRWiiPCfKulXYx73qrmm/HZJPzKzJ81sQ9HNjGN+Nm366PTp8wru53gVZ25upONmlm6a166aGa/zVkT4x5v9p5mGHFa6+yclfUrSNdnbW0zMhGZubpRxZpZuCtXOeJ23IsLfK2nhmMcfkrS/gD7G5e77s9sBSfer+WYf7h+dJDW7HSi4n99pppmbx5tZWk3w2jXTjNdFhP8JSUvNbLGZTZf0aUm7CujjXcxsVvZFjMxslqTVar7Zh3dJWp/dXy/pgQJ7+T3NMnNzuZmlVfBr12wzXhfyI59sKONfJLVI6nT3bzS8iXGY2Uc0crSXRiYxvaPI3szsTkmrNHLWV7+kGyT9p6R7JH1Y0iuSrnD3hn/xVqa3VRp56/q7mZtHP2M3uLcLJD0q6RlJw9nizRr5fF3Ya5foa50KeN34hR8QFL/wA4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q1P8D6+E2hIAP97kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "plt.imshow(x_train[0])\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.2454 - acc: 0.9246 - val_loss: 0.1041 - val_acc: 0.9683\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1036 - acc: 0.9689 - val_loss: 0.0863 - val_acc: 0.9739\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0763 - acc: 0.9776 - val_loss: 0.0712 - val_acc: 0.9781\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0613 - acc: 0.9813 - val_loss: 0.0915 - val_acc: 0.9743\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0508 - acc: 0.9855 - val_loss: 0.0747 - val_acc: 0.9815\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0447 - acc: 0.9866 - val_loss: 0.0951 - val_acc: 0.9785\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0374 - acc: 0.9889 - val_loss: 0.0917 - val_acc: 0.9798\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0354 - acc: 0.9897 - val_loss: 0.0864 - val_acc: 0.9809\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0318 - acc: 0.9906 - val_loss: 0.0922 - val_acc: 0.9811\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0281 - acc: 0.9919 - val_loss: 0.0859 - val_acc: 0.9834\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0258 - acc: 0.9923 - val_loss: 0.1012 - val_acc: 0.9817\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0266 - acc: 0.9928 - val_loss: 0.0999 - val_acc: 0.9810\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0243 - acc: 0.9931 - val_loss: 0.0962 - val_acc: 0.9832\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0214 - acc: 0.9940 - val_loss: 0.1098 - val_acc: 0.9821\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0205 - acc: 0.9946 - val_loss: 0.1004 - val_acc: 0.9832\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0202 - acc: 0.9946 - val_loss: 0.1045 - val_acc: 0.9842\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0204 - acc: 0.9948 - val_loss: 0.1042 - val_acc: 0.9836\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0192 - acc: 0.9952 - val_loss: 0.1162 - val_acc: 0.9828\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0187 - acc: 0.9952 - val_loss: 0.1169 - val_acc: 0.9821\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0185 - acc: 0.9954 - val_loss: 0.1273 - val_acc: 0.9815\n",
      "Test loss: 0.12734949334023926\n",
      "Test accuracy: 0.9815\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv Net\n",
    "Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if backend.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 111s 2ms/step - loss: 0.2741 - acc: 0.9166 - val_loss: 0.0577 - val_acc: 0.9819\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 109s 2ms/step - loss: 0.0910 - acc: 0.9728 - val_loss: 0.0428 - val_acc: 0.9858\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 113s 2ms/step - loss: 0.0668 - acc: 0.9803 - val_loss: 0.0384 - val_acc: 0.9878\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.0547 - acc: 0.9839 - val_loss: 0.0354 - val_acc: 0.9869\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 108s 2ms/step - loss: 0.0462 - acc: 0.9864 - val_loss: 0.0322 - val_acc: 0.9896\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 108s 2ms/step - loss: 0.0412 - acc: 0.9875 - val_loss: 0.0306 - val_acc: 0.9890\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 111s 2ms/step - loss: 0.0365 - acc: 0.9883 - val_loss: 0.0264 - val_acc: 0.9913\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 111s 2ms/step - loss: 0.0335 - acc: 0.9892 - val_loss: 0.0287 - val_acc: 0.9906\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 116s 2ms/step - loss: 0.0312 - acc: 0.9902 - val_loss: 0.0264 - val_acc: 0.9910\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 124s 2ms/step - loss: 0.0299 - acc: 0.9913 - val_loss: 0.0279 - val_acc: 0.9907\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 124s 2ms/step - loss: 0.0282 - acc: 0.9912 - val_loss: 0.0272 - val_acc: 0.9913\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 124s 2ms/step - loss: 0.0263 - acc: 0.9916 - val_loss: 0.0257 - val_acc: 0.9922\n",
      "Test loss: 0.025738338507244406\n",
      "Test accuracy: 0.9922\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## With noise added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adding noise to the image\n",
    "(noisy_xtrain, noisy_ytrain), (noisy_xtest, noisy_ytest) = mnist.load_data()\n",
    "noisy_xtrain = noisy_xtrain+np.random.normal(noisy_xtrain, 50)\n",
    "noisy_xtest = noisy_xtest+np.random.normal(noisy_xtest, 50)\n",
    "plt.imshow(noisy_xtrain[0])\n",
    "\n",
    "noisy_xtrain = noisy_xtrain.reshape(60000, 784)\n",
    "noisy_xtest = noisy_xtest.reshape(10000, 784)\n",
    "noisy_xtrain = noisy_xtrain.astype('float32')\n",
    "noisy_xtest = noisy_xtest.astype('float32')\n",
    "noisy_xtrain /= 255\n",
    "noisy_xtest /= 255\n",
    "print(noisy_xtrain.shape[0], 'train samples')\n",
    "print(noisy_xtest.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.2629 - acc: 0.9194 - val_loss: 0.1190 - val_acc: 0.9631\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.1036 - acc: 0.9677 - val_loss: 0.1007 - val_acc: 0.9698\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0664 - acc: 0.9796 - val_loss: 0.1113 - val_acc: 0.9697\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0465 - acc: 0.9860 - val_loss: 0.1174 - val_acc: 0.9735\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0356 - acc: 0.9887 - val_loss: 0.1218 - val_acc: 0.9749\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0297 - acc: 0.9909 - val_loss: 0.1347 - val_acc: 0.9738\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0279 - acc: 0.9919 - val_loss: 0.1398 - val_acc: 0.9741\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0220 - acc: 0.9931 - val_loss: 0.1453 - val_acc: 0.9741\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0193 - acc: 0.9946 - val_loss: 0.1447 - val_acc: 0.9760\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0209 - acc: 0.9945 - val_loss: 0.1580 - val_acc: 0.9758\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0171 - acc: 0.9952 - val_loss: 0.1683 - val_acc: 0.9739\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0175 - acc: 0.9954 - val_loss: 0.1879 - val_acc: 0.9730\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0180 - acc: 0.9952 - val_loss: 0.1607 - val_acc: 0.9761\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0156 - acc: 0.9959 - val_loss: 0.1803 - val_acc: 0.9756\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0158 - acc: 0.9960 - val_loss: 0.1832 - val_acc: 0.9775\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 92us/step - loss: 0.0164 - acc: 0.9963 - val_loss: 0.1970 - val_acc: 0.9748\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0143 - acc: 0.9966 - val_loss: 0.2006 - val_acc: 0.9763\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0148 - acc: 0.9967 - val_loss: 0.2035 - val_acc: 0.9753\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0146 - acc: 0.9967 - val_loss: 0.1743 - val_acc: 0.9785\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0107 - acc: 0.9973 - val_loss: 0.1991 - val_acc: 0.9770\n",
      "Test loss: 0.025738338507244406\n",
      "Test accuracy: 0.9922\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "\n",
    "noisy_ytrain = keras.utils.to_categorical(noisy_ytrain, num_classes)\n",
    "noisy_ytest = keras.utils.to_categorical(noisy_ytest, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(noisy_xtrain, noisy_ytrain,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(noisy_xtest, noisy_ytest))\n",
    "score50 = model.evaluate(noisy_xtest, noisy_ytest, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.2442 - acc: 0.9247 - val_loss: 0.1154 - val_acc: 0.9649\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.1046 - acc: 0.9684 - val_loss: 0.0761 - val_acc: 0.9783\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0798 - acc: 0.9766 - val_loss: 0.0812 - val_acc: 0.9768\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 92us/step - loss: 0.0652 - acc: 0.9810 - val_loss: 0.0791 - val_acc: 0.9771\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0571 - acc: 0.9829 - val_loss: 0.0694 - val_acc: 0.9823\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0478 - acc: 0.9865 - val_loss: 0.0901 - val_acc: 0.9799\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0448 - acc: 0.9871 - val_loss: 0.0821 - val_acc: 0.9813\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.0413 - acc: 0.9884 - val_loss: 0.0825 - val_acc: 0.9806\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0354 - acc: 0.9902 - val_loss: 0.0854 - val_acc: 0.9816\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.0367 - acc: 0.9907 - val_loss: 0.0956 - val_acc: 0.9823\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0359 - acc: 0.9907 - val_loss: 0.0988 - val_acc: 0.9819\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0320 - acc: 0.9915 - val_loss: 0.1092 - val_acc: 0.9814\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0302 - acc: 0.9920 - val_loss: 0.0903 - val_acc: 0.9839\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0323 - acc: 0.9923 - val_loss: 0.0881 - val_acc: 0.9845\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0288 - acc: 0.9932 - val_loss: 0.0990 - val_acc: 0.9855\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.0301 - acc: 0.9930 - val_loss: 0.1245 - val_acc: 0.9804\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0305 - acc: 0.9931 - val_loss: 0.1017 - val_acc: 0.9833\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.0268 - acc: 0.9934 - val_loss: 0.1136 - val_acc: 0.9826\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0285 - acc: 0.9936 - val_loss: 0.1077 - val_acc: 0.9839\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0265 - acc: 0.9939 - val_loss: 0.1347 - val_acc: 0.9798\n",
      "10\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.2453 - acc: 0.9247 - val_loss: 0.1051 - val_acc: 0.9675\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.1049 - acc: 0.9687 - val_loss: 0.0911 - val_acc: 0.9729\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0745 - acc: 0.9782 - val_loss: 0.0882 - val_acc: 0.9762\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0600 - acc: 0.9825 - val_loss: 0.0760 - val_acc: 0.9811\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0506 - acc: 0.9854 - val_loss: 0.0863 - val_acc: 0.9779\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0424 - acc: 0.9873 - val_loss: 0.0823 - val_acc: 0.9820\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0370 - acc: 0.9890 - val_loss: 0.0886 - val_acc: 0.9808\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0361 - acc: 0.9896 - val_loss: 0.1118 - val_acc: 0.9791\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 92us/step - loss: 0.0285 - acc: 0.9920 - val_loss: 0.0995 - val_acc: 0.9805\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0277 - acc: 0.9919 - val_loss: 0.1009 - val_acc: 0.9816\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0274 - acc: 0.9925 - val_loss: 0.1057 - val_acc: 0.9816\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0239 - acc: 0.9935 - val_loss: 0.1033 - val_acc: 0.9838\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0227 - acc: 0.9939 - val_loss: 0.1144 - val_acc: 0.9819\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.0222 - acc: 0.9942 - val_loss: 0.1073 - val_acc: 0.9828\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0232 - acc: 0.9945 - val_loss: 0.1278 - val_acc: 0.9807\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0234 - acc: 0.9946 - val_loss: 0.1158 - val_acc: 0.9830\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0218 - acc: 0.9945 - val_loss: 0.1174 - val_acc: 0.9831\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0204 - acc: 0.9948 - val_loss: 0.1205 - val_acc: 0.9823\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0201 - acc: 0.9950 - val_loss: 0.1194 - val_acc: 0.9829\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0187 - acc: 0.9953 - val_loss: 0.1418 - val_acc: 0.9804\n",
      "20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.2456 - acc: 0.9258 - val_loss: 0.1224 - val_acc: 0.9616\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.1030 - acc: 0.9688 - val_loss: 0.0872 - val_acc: 0.9725\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0704 - acc: 0.9780 - val_loss: 0.0847 - val_acc: 0.9772\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0543 - acc: 0.9832 - val_loss: 0.0865 - val_acc: 0.9775\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0441 - acc: 0.9864 - val_loss: 0.0792 - val_acc: 0.9813\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0389 - acc: 0.9887 - val_loss: 0.1052 - val_acc: 0.9774\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0330 - acc: 0.9900 - val_loss: 0.0879 - val_acc: 0.9819\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0297 - acc: 0.9916 - val_loss: 0.1027 - val_acc: 0.9794\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0268 - acc: 0.9924 - val_loss: 0.1060 - val_acc: 0.9800\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0232 - acc: 0.9936 - val_loss: 0.1106 - val_acc: 0.9823\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0232 - acc: 0.9937 - val_loss: 0.1216 - val_acc: 0.9801\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0202 - acc: 0.9944 - val_loss: 0.1156 - val_acc: 0.9824\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.0190 - acc: 0.9950 - val_loss: 0.1234 - val_acc: 0.9817\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0190 - acc: 0.9953 - val_loss: 0.1315 - val_acc: 0.9815\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0178 - acc: 0.9953 - val_loss: 0.1366 - val_acc: 0.9799\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0184 - acc: 0.9954 - val_loss: 0.1331 - val_acc: 0.9816\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0187 - acc: 0.9959 - val_loss: 0.1380 - val_acc: 0.9814\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0167 - acc: 0.9959 - val_loss: 0.1655 - val_acc: 0.9787\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0163 - acc: 0.9963 - val_loss: 0.1400 - val_acc: 0.9816\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0157 - acc: 0.9963 - val_loss: 0.1394 - val_acc: 0.9817\n",
      "30\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.2511 - acc: 0.9224 - val_loss: 0.1185 - val_acc: 0.9636\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.1022 - acc: 0.9695 - val_loss: 0.0926 - val_acc: 0.9715\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0703 - acc: 0.9786 - val_loss: 0.0906 - val_acc: 0.9745\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0509 - acc: 0.9846 - val_loss: 0.0962 - val_acc: 0.9768\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0411 - acc: 0.9878 - val_loss: 0.1001 - val_acc: 0.9771\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0354 - acc: 0.9896 - val_loss: 0.1190 - val_acc: 0.9765\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0291 - acc: 0.9916 - val_loss: 0.1351 - val_acc: 0.9753\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0278 - acc: 0.9919 - val_loss: 0.1167 - val_acc: 0.9793\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0231 - acc: 0.9931 - val_loss: 0.1354 - val_acc: 0.9777\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0225 - acc: 0.9941 - val_loss: 0.1256 - val_acc: 0.9781\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0219 - acc: 0.9937 - val_loss: 0.1196 - val_acc: 0.9795\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0188 - acc: 0.9949 - val_loss: 0.1467 - val_acc: 0.9779\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0183 - acc: 0.9949 - val_loss: 0.1169 - val_acc: 0.9817\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0160 - acc: 0.9960 - val_loss: 0.1302 - val_acc: 0.9803\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.0170 - acc: 0.9956 - val_loss: 0.1336 - val_acc: 0.9803\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0162 - acc: 0.9961 - val_loss: 0.1525 - val_acc: 0.9813\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0173 - acc: 0.9958 - val_loss: 0.1358 - val_acc: 0.9817\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0184 - acc: 0.9959 - val_loss: 0.1516 - val_acc: 0.9809\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0168 - acc: 0.9968 - val_loss: 0.1501 - val_acc: 0.9806\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0155 - acc: 0.9966 - val_loss: 0.1520 - val_acc: 0.9813\n",
      "40\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.2570 - acc: 0.9208 - val_loss: 0.1107 - val_acc: 0.9655\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.1000 - acc: 0.9698 - val_loss: 0.0960 - val_acc: 0.9730\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0659 - acc: 0.9800 - val_loss: 0.0885 - val_acc: 0.9773\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0485 - acc: 0.9853 - val_loss: 0.0943 - val_acc: 0.9765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0398 - acc: 0.9880 - val_loss: 0.1175 - val_acc: 0.9741\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0327 - acc: 0.9901 - val_loss: 0.1230 - val_acc: 0.9762\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0274 - acc: 0.9919 - val_loss: 0.1150 - val_acc: 0.9791\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0231 - acc: 0.9928 - val_loss: 0.1392 - val_acc: 0.9762\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 92us/step - loss: 0.0210 - acc: 0.9941 - val_loss: 0.1352 - val_acc: 0.9764\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0206 - acc: 0.9939 - val_loss: 0.1393 - val_acc: 0.9778\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0178 - acc: 0.9952 - val_loss: 0.1532 - val_acc: 0.9780\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0210 - acc: 0.9948 - val_loss: 0.1426 - val_acc: 0.9780\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0138 - acc: 0.9963 - val_loss: 0.1669 - val_acc: 0.9780\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0179 - acc: 0.9958 - val_loss: 0.1812 - val_acc: 0.9739\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.0180 - acc: 0.9957 - val_loss: 0.1570 - val_acc: 0.9788\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0157 - acc: 0.9963 - val_loss: 0.1674 - val_acc: 0.9773\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0148 - acc: 0.9967 - val_loss: 0.1753 - val_acc: 0.9763\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0130 - acc: 0.9969 - val_loss: 0.1723 - val_acc: 0.9787\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.0130 - acc: 0.9970 - val_loss: 0.1848 - val_acc: 0.9789\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.0134 - acc: 0.9970 - val_loss: 0.1844 - val_acc: 0.9771\n",
      "50\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.2568 - acc: 0.9209 - val_loss: 0.1087 - val_acc: 0.9670\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.0995 - acc: 0.9695 - val_loss: 0.1087 - val_acc: 0.9686\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.0651 - acc: 0.9795 - val_loss: 0.0930 - val_acc: 0.9757\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0458 - acc: 0.9859 - val_loss: 0.1074 - val_acc: 0.9758\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0355 - acc: 0.9891 - val_loss: 0.1130 - val_acc: 0.9765\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0264 - acc: 0.9919 - val_loss: 0.1243 - val_acc: 0.9776\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0284 - acc: 0.9919 - val_loss: 0.1278 - val_acc: 0.9770\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0222 - acc: 0.9934 - val_loss: 0.1481 - val_acc: 0.9758\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0217 - acc: 0.9939 - val_loss: 0.1446 - val_acc: 0.9752\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0187 - acc: 0.9945 - val_loss: 0.1705 - val_acc: 0.9738\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0198 - acc: 0.9951 - val_loss: 0.1694 - val_acc: 0.9762\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0170 - acc: 0.9953 - val_loss: 0.1504 - val_acc: 0.9783\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0150 - acc: 0.9961 - val_loss: 0.1500 - val_acc: 0.9791\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0152 - acc: 0.9964 - val_loss: 0.1703 - val_acc: 0.9788\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0164 - acc: 0.9961 - val_loss: 0.1725 - val_acc: 0.9775\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0160 - acc: 0.9964 - val_loss: 0.1527 - val_acc: 0.9783\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0142 - acc: 0.9968 - val_loss: 0.1808 - val_acc: 0.9758\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0146 - acc: 0.9966 - val_loss: 0.1803 - val_acc: 0.9771\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0121 - acc: 0.9970 - val_loss: 0.1786 - val_acc: 0.9785\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0107 - acc: 0.9976 - val_loss: 0.1929 - val_acc: 0.9778\n",
      "60\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.2710 - acc: 0.9158 - val_loss: 0.1209 - val_acc: 0.9612\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.1028 - acc: 0.9690 - val_loss: 0.1163 - val_acc: 0.9660\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0622 - acc: 0.9803 - val_loss: 0.1080 - val_acc: 0.9713\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0449 - acc: 0.9865 - val_loss: 0.1304 - val_acc: 0.9691\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0359 - acc: 0.9889 - val_loss: 0.1276 - val_acc: 0.9761\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0287 - acc: 0.9913 - val_loss: 0.1359 - val_acc: 0.9743\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0243 - acc: 0.9930 - val_loss: 0.1532 - val_acc: 0.9718\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0218 - acc: 0.9934 - val_loss: 0.1568 - val_acc: 0.9755\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0201 - acc: 0.9939 - val_loss: 0.1539 - val_acc: 0.9761\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0183 - acc: 0.9950 - val_loss: 0.1709 - val_acc: 0.9752\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0177 - acc: 0.9951 - val_loss: 0.1730 - val_acc: 0.9747\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 92us/step - loss: 0.0174 - acc: 0.9951 - val_loss: 0.1857 - val_acc: 0.9746\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.0137 - acc: 0.9965 - val_loss: 0.2152 - val_acc: 0.9735\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.0165 - acc: 0.9959 - val_loss: 0.2054 - val_acc: 0.9732\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0141 - acc: 0.9965 - val_loss: 0.2098 - val_acc: 0.9756\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0150 - acc: 0.9965 - val_loss: 0.1844 - val_acc: 0.9767\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0132 - acc: 0.9967 - val_loss: 0.2037 - val_acc: 0.9752\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0109 - acc: 0.9972 - val_loss: 0.2258 - val_acc: 0.9752\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0129 - acc: 0.9969 - val_loss: 0.2134 - val_acc: 0.9762\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0125 - acc: 0.9971 - val_loss: 0.2267 - val_acc: 0.9741\n",
      "70\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.2784 - acc: 0.9137 - val_loss: 0.1517 - val_acc: 0.9531\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.1061 - acc: 0.9680 - val_loss: 0.1174 - val_acc: 0.9675\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.0632 - acc: 0.9807 - val_loss: 0.1097 - val_acc: 0.9707\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0427 - acc: 0.9871 - val_loss: 0.1267 - val_acc: 0.9703\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0341 - acc: 0.9896 - val_loss: 0.1424 - val_acc: 0.9718\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0284 - acc: 0.9917 - val_loss: 0.1522 - val_acc: 0.9709\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0242 - acc: 0.9931 - val_loss: 0.1515 - val_acc: 0.9725\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0198 - acc: 0.9941 - val_loss: 0.1508 - val_acc: 0.9727\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0176 - acc: 0.9949 - val_loss: 0.1646 - val_acc: 0.9716\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0186 - acc: 0.9949 - val_loss: 0.1765 - val_acc: 0.9722\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0166 - acc: 0.9951 - val_loss: 0.1812 - val_acc: 0.9737\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0182 - acc: 0.9953 - val_loss: 0.1654 - val_acc: 0.9758\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0146 - acc: 0.9963 - val_loss: 0.1728 - val_acc: 0.9754\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0160 - acc: 0.9962 - val_loss: 0.1903 - val_acc: 0.9759\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0149 - acc: 0.9961 - val_loss: 0.2177 - val_acc: 0.9728\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0138 - acc: 0.9966 - val_loss: 0.2299 - val_acc: 0.9697\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0119 - acc: 0.9970 - val_loss: 0.2240 - val_acc: 0.9735\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0122 - acc: 0.9971 - val_loss: 0.1925 - val_acc: 0.9750\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0130 - acc: 0.9967 - val_loss: 0.2127 - val_acc: 0.9737\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0110 - acc: 0.9975 - val_loss: 0.2144 - val_acc: 0.9754\n",
      "80\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.2823 - acc: 0.9112 - val_loss: 0.1380 - val_acc: 0.9570\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.1100 - acc: 0.9664 - val_loss: 0.1097 - val_acc: 0.9677\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0634 - acc: 0.9806 - val_loss: 0.1216 - val_acc: 0.9702\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0457 - acc: 0.9859 - val_loss: 0.1161 - val_acc: 0.9729\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0334 - acc: 0.9891 - val_loss: 0.1461 - val_acc: 0.9709\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0262 - acc: 0.9918 - val_loss: 0.1588 - val_acc: 0.9706\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0225 - acc: 0.9932 - val_loss: 0.1791 - val_acc: 0.9699\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0230 - acc: 0.9930 - val_loss: 0.1925 - val_acc: 0.9703\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0186 - acc: 0.9951 - val_loss: 0.1907 - val_acc: 0.9725\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0195 - acc: 0.9947 - val_loss: 0.1832 - val_acc: 0.9726\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0159 - acc: 0.9955 - val_loss: 0.1999 - val_acc: 0.9732\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0149 - acc: 0.9959 - val_loss: 0.2067 - val_acc: 0.9716\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0142 - acc: 0.9966 - val_loss: 0.1914 - val_acc: 0.9740\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0147 - acc: 0.9962 - val_loss: 0.2106 - val_acc: 0.9733\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0141 - acc: 0.9965 - val_loss: 0.2040 - val_acc: 0.9744\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0139 - acc: 0.9966 - val_loss: 0.2063 - val_acc: 0.9750\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0116 - acc: 0.9970 - val_loss: 0.2421 - val_acc: 0.9730\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0128 - acc: 0.9970 - val_loss: 0.2318 - val_acc: 0.9719\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0122 - acc: 0.9971 - val_loss: 0.2322 - val_acc: 0.9727\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0118 - acc: 0.9970 - val_loss: 0.2316 - val_acc: 0.9727\n",
      "90\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.2988 - acc: 0.9058 - val_loss: 0.1402 - val_acc: 0.9567\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.1095 - acc: 0.9668 - val_loss: 0.1293 - val_acc: 0.9625\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.0630 - acc: 0.9800 - val_loss: 0.1353 - val_acc: 0.9658\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0432 - acc: 0.9858 - val_loss: 0.1507 - val_acc: 0.9670\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0328 - acc: 0.9900 - val_loss: 0.1452 - val_acc: 0.9698\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0253 - acc: 0.9926 - val_loss: 0.1854 - val_acc: 0.9693\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0257 - acc: 0.9922 - val_loss: 0.1818 - val_acc: 0.9701\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0221 - acc: 0.9934 - val_loss: 0.1865 - val_acc: 0.9685\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0187 - acc: 0.9946 - val_loss: 0.1937 - val_acc: 0.9724\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0174 - acc: 0.9950 - val_loss: 0.2115 - val_acc: 0.9710\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0182 - acc: 0.9953 - val_loss: 0.2230 - val_acc: 0.9680\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0150 - acc: 0.9959 - val_loss: 0.2305 - val_acc: 0.9681\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0152 - acc: 0.9962 - val_loss: 0.2472 - val_acc: 0.9687\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0155 - acc: 0.9960 - val_loss: 0.2447 - val_acc: 0.9714\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0152 - acc: 0.9963 - val_loss: 0.2494 - val_acc: 0.9696\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0132 - acc: 0.9969 - val_loss: 0.2637 - val_acc: 0.9693\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0123 - acc: 0.9969 - val_loss: 0.2772 - val_acc: 0.9677\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.0153 - acc: 0.9967 - val_loss: 0.2452 - val_acc: 0.9717\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0115 - acc: 0.9975 - val_loss: 0.2547 - val_acc: 0.9726\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0098 - acc: 0.9978 - val_loss: 0.2656 - val_acc: 0.9707\n"
     ]
    }
   ],
   "source": [
    "parameters = range(0, 100, 10)\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "allscores=[]\n",
    "\n",
    "for x in parameters:\n",
    "    (noisy_xtrain, noisy_ytrain), (noisy_xtest, noisy_ytest) = mnist.load_data()\n",
    "    noisy_xtrain = noisy_xtrain+np.random.normal(noisy_xtrain, x)\n",
    "    noisy_xtest = noisy_xtest+np.random.normal(noisy_xtest, x)\n",
    "    print(x)\n",
    "\n",
    "    noisy_xtrain = noisy_xtrain.reshape(60000, 784)\n",
    "    noisy_xtest = noisy_xtest.reshape(10000, 784)\n",
    "    noisy_xtrain = noisy_xtrain.astype('float32')\n",
    "    noisy_xtest = noisy_xtest.astype('float32')\n",
    "    noisy_xtrain /= 255\n",
    "    noisy_xtest /= 255\n",
    "    noisy_ytrain = keras.utils.to_categorical(noisy_ytrain, num_classes)\n",
    "    noisy_ytest = keras.utils.to_categorical(noisy_ytest, num_classes)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(noisy_xtrain, noisy_ytrain,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(noisy_xtest, noisy_ytest))\n",
    "    x = model.evaluate(noisy_xtest, noisy_ytest, verbose=0)\n",
    "    allscores.append(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13468216578953485, 0.9798], [0.14183423149677807, 0.9804], [0.13937270646047709, 0.9817], [0.1519822527994323, 0.9813], [0.18443236458955412, 0.9771], [0.19293417661142176, 0.9778], [0.22671141400414271, 0.9741], [0.21435715573724265, 0.9754], [0.23157701590922047, 0.9727], [0.26561329689156044, 0.9707]]\n"
     ]
    }
   ],
   "source": [
    "print(allscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(allscores)\n",
    "plt.title('Test Accuracy')\n",
    "plt.axis([0,10,.97, 1])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(allscores)\n",
    "plt.title('Test Lost')\n",
    "plt.axis([0,10,0.10, 0.27])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## As expected, the introduction of more noise (looped in increments of 10 from 0 to 100 above) \n",
    "## leads to higher test lost and lower test accuracy in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
